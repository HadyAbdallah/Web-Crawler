# Web Crawler
This project involves developing a web crawler to gather and analyze data from various websites. The crawler is designed to navigate web pages, extract relevant information, and store it in a structured format. The repository contains all the necessary code for configuring, running, and managing the crawler, as well as guidelines for processing and analyzing the collected data. Ideal for data scientists and developers interested in web scraping and data extraction techniques.

## Features
  - A web crawler that crawl wikipedia starting from the following 2 seeded
  https://en.wikipedia.org/wiki/List_of_pharaohs
  - Build the inverted index for visited pages
  - get a query ( set of a number of words)
  - compute the cosine similarity between each file and the query
  - rank the top k=10 files according to the value of the cosin similarity
